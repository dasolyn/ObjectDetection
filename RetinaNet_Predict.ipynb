{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "이미 훈련된 RetinaNet 모델을 로드하여 객체 검출을 하는 과정입니다. Train시와 동일한 환경을 구축하여야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from six.moves import zip\n",
    "import time\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.optimizers import adam\n",
    "from keras_retinanet.losses import focal, smooth_l1\n",
    "from keras_retinanet.models.resnet import ResNet50RetinaNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 설정\n",
    "\n",
    "아래는 데이터셋 및 객체 검출 설정에 필요한 환경 변수입니다. 사용하는 데이터셋 및 모델에 맞춰서 변경하시기 바랍니다.\n",
    "\n",
    " - `classes` : 데이터내에 구성하는 모든 클래스의 정보를 담은 dict입니다. 키는 클래스의 일련변호, 값은 각 클래스의 이름으로로 지정해야 합니다. 일련번호는 숫자 0부터 중복과 누락없이 채워져야 합니다. 훈련시에 사용한 `classes` dict를 키-값 반전해서 사용하면 됩니다.\n",
    " - `weight_file_path` : 입력 weight 파일의 경로 및 이름을 지정합니다.\n",
    " - `predict_source` : 객체 검출을 할 대상 이미지 파일이 있는 디렉토리를 지정합니다.\n",
    " - `predict_result` : 객체 검출 결과가 출력될 디렉토리를 지정합니다. 자동으로 해당 디렉토리를 생성하지 않으므로 미리 생성해두셔야 합니다.\n",
    " - `bbox_threshold` : 검출된 경계 상자를 양성(positive)로 판정할 임계값입니다.\n",
    " - `resize` : 이미지가 지나치게 크면 리사이즈하여 검출할지를 지정하는 부울 값입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = None\n",
    "weight_file_path = './retinanet.h5'\n",
    "predict_source = './images'\n",
    "predict_result = './results'\n",
    "bbox_threshold = 0.5\n",
    "resize = True\n",
    "\n",
    "if classes is None:\n",
    "    classes = {0: 'aeroplane', 1: 'bicycle', 2: 'bird', 3: 'boat', 4: 'bottle',\n",
    "               5: 'bus', 6: 'car', 7: 'cat', 8: 'chair', 9: 'cow',\n",
    "               10: 'diningtable', 11: 'dog', 12: 'horse', 13: 'motorbike', 14: 'person',\n",
    "               15: 'pottedplant', 16: 'sheep', 17: 'sofa', 18: 'train', 19: 'tvmonitor'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 빌드\n",
    "\n",
    "RetinaNet with ResNet50 모델을 빌드하고 모델의 weight 파일을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input((None, None, 3))\n",
    "model = ResNet50RetinaNet(image_input, num_classes=len(classes), weights='imagenet', nms=True)\n",
    "\n",
    "model.load_weights(weight_file_path)\n",
    "model.compile(\n",
    "    loss={'regression': smooth_l1(), 'classification': focal()},\n",
    "    optimizer=adam(lr=1e-5, clipnorm=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검출 시작\n",
    "\n",
    "로드한 모델을 이용해서 소스 이미지의 객체 검출을 실행하고 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, min_side, max_side):\n",
    "    (rows, cols, _) = img.shape\n",
    "    smallest_side = min(rows, cols)\n",
    "    scale = min_side / smallest_side\n",
    "    largest_side = max(rows, cols)\n",
    "    if largest_side * scale > max_side:\n",
    "        scale = max_side / largest_side\n",
    "\n",
    "    img = cv2.resize(img, None, fx=scale, fy=scale)\n",
    "\n",
    "    return img, scale\n",
    "\n",
    "for dir_path, _, filenames in os.walk(predict_source):\n",
    "    for filename in filenames:\n",
    "        if not filename.endswith(('.jpg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # 이미지 로드\n",
    "        start = time.time()\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        print(file_path)\n",
    "        img = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # 정규화 및 리사이즈\n",
    "        predict = img.copy()\n",
    "        cv2.normalize(img, predict, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n",
    "        scale = 1\n",
    "        if resize:\n",
    "            predict, scale = resize_image(predict, 720, 1280)\n",
    "        predict = np.expand_dims(predict, axis=0)\n",
    "\n",
    "        # 검출\n",
    "        _, _, detections = model.predict_on_batch(predict)\n",
    "\n",
    "        # 결과 후처리\n",
    "        predicted_labels = np.argmax(detections[0, :, 4:], axis=1)\n",
    "        scores = np.max(detections[0, :, 4:], axis=1)\n",
    "\n",
    "        for idx, (label, score) in enumerate(zip(predicted_labels, scores)):\n",
    "            if score < bbox_threshold:\n",
    "                continue\n",
    "            b = detections[0, idx, :4] / scale\n",
    "            b = b.astype(int)\n",
    "\n",
    "            print('Label: {}, Score: {}, LTRB of the boundary box: {}, {}, {}, {}'.format(classes[label], score, b[0], b[1], b[2], b[3]))\n",
    "\n",
    "            cv2.rectangle(img, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 3)\n",
    "            caption = \"{} {:.3f}\".format(classes[label], score)\n",
    "            cv2.putText(img, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 0, 0), 3)\n",
    "            cv2.putText(img, caption, (b[0], b[1] - 10), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imwrite(os.path.join(predict_result, filename), img)\n",
    "\n",
    "        print(\"Processing time: {}\".format(time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
